{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "import spacy\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEHIND_THE_WORDS_DIR = \"./\"\n",
    "DATA_DIR = os.path.join(BEHIND_THE_WORDS_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_word2vec import load_word2vec\n",
    "\n",
    "w2v_model_path = os.path.join(BEHIND_THE_WORDS_DIR, \"data/gensim/word2vec-google-news-300.gz\")\n",
    "word2vec = load_word2vec(w2v_model_path, \"http://127.0.0.1:7070\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_LENGTH = 384\n",
    "\n",
    "def process_text(text, max_token_length=None):\n",
    "  if max_token_length == None:\n",
    "    max_token_length = MAX_TOKEN_LENGTH\n",
    "\n",
    "  doc = nlp(text)\n",
    "  words = [token.lower_ for token in doc]\n",
    "  embeddings = word2vec.get_vec(words).tolist()[:MAX_TOKEN_LENGTH]\n",
    "  padding = [[0] * 300] * (MAX_TOKEN_LENGTH - len(embeddings))\n",
    "\n",
    "  return embeddings + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loader.JSONLDataloader as JSONLDataloader\n",
    "reload(JSONLDataloader)\n",
    "\n",
    "dataset_jsonl_dataloader = JSONLDataloader.JSONLDataloader(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor.WordEmbeddingPreprocessor as WordEmbeddingPreprocessor\n",
    "\n",
    "reload(WordEmbeddingPreprocessor)\n",
    "\n",
    "word_embedding_preprocessor = WordEmbeddingPreprocessor.WordEmbeddingPreprocessor(process_text, dataset_jsonl_dataloader, _dir = DATA_DIR, in_folders=[\"cnn\"], out_folders=[\"cnn\", \"word-embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_preprocessor.preprocess(\"own\", max_token_length=MAX_TOKEN_LENGTH)\n",
    "word_embedding_preprocessor.preprocess(\"essayforum\", max_token_length=MAX_TOKEN_LENGTH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
