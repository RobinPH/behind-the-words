{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "import spacy\n",
    "from gensim import models\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEHIND_THE_WORDS_DIR = \"./\"\n",
    "DATA_DIR = os.path.join(BEHIND_THE_WORDS_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_word2vec import load_word2vec\n",
    "\n",
    "w2v_model_path = os.path.join(BEHIND_THE_WORDS_DIR, \"metaphor/data/gensim/word2vec-google-news-300.gz\")\n",
    "word2vec = load_word2vec(w2v_model_path, \"http://127.0.0.1:7070\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dir import get_latest_file_in_dir, get_filename\n",
    "\n",
    "LATEST_CNN_MODEL = get_latest_file_in_dir(\"./models/cnn/\")\n",
    "CNN_MODEL_NAME = get_filename(LATEST_CNN_MODEL)\n",
    "model_cnn = tf.keras.saving.load_model(LATEST_CNN_MODEL, compile=True, safe_mode=True)\n",
    "print(f\"Using CNN Model {LATEST_CNN_MODEL}\")\n",
    "\n",
    "MAX_TOKEN_LENGTH = 384\n",
    "\n",
    "def process_text(text, max_token_length=None):\n",
    "  if max_token_length == None:\n",
    "    max_token_length = MAX_TOKEN_LENGTH\n",
    "    \n",
    "  doc = _nlp(text)\n",
    "  words = [token.lower_ for token in doc]\n",
    "  embeddings = word2vec.get_vec(words).tolist()[:MAX_TOKEN_LENGTH]\n",
    "  padding = [[0] * 300] * (MAX_TOKEN_LENGTH - len(embeddings))\n",
    "\n",
    "  return embeddings + padding\n",
    "\n",
    "def predict_cnn(model_cnn, text):\n",
    "  data = np.array([process_text(text)])\n",
    "  data = data.reshape(-1, *data.shape[1:], 1)\n",
    "\n",
    "  return model_cnn.predict(data, verbose=None).tolist()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loader.JSONLDataloader as JSONLDataloader\n",
    "reload(JSONLDataloader)\n",
    "\n",
    "dataset_jsonl_dataloader = JSONLDataloader.JSONLDataloader(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor.CNNPredictionPreprocessor as CNNPredictionPreprocessor\n",
    "\n",
    "reload(CNNPredictionPreprocessor)\n",
    "\n",
    "cnn_prediction_preprocessor = CNNPredictionPreprocessor.CNNPredictionPreprocessor(process_text, dataset_jsonl_dataloader, _dir = DATA_DIR, in_folders=[\"rf-cnn\"], out_folders=[\"rf-cnn\", \"cnn-prediction\", CNN_MODEL_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_prediction_preprocessor.preprocess(\"essayforum\", model_cnn)\n",
    "cnn_prediction_preprocessor.preprocess(\"own\", model_cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
